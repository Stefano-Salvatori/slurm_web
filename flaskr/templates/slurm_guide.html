<!DOCTYPE html>
<html lang="en">

{% with title="Slurm Web | Guide" %}{% include "head.html" %}{% endwith %}

<body>
    {% with page="guide" %}{% include "navigation.html" %}{% endwith %}
    <div class="container-fluid p-3">
        <h1 id="slurm-guide">Cluster Usage Guide</h1>
        <p>Our cluster includes 3 servers:</p>
        <ul>
            <li>137.204.107.40 (<em>faretra</em>)
                <ul>
                    <li>4 GPU Nvidia Geforece RTX 3090 (24Gb)</li>
                    <li>ssh on port 37335</li>
                </ul>
            </li>
            <li>137.204.107.43 (<em>cloudifaicdlw001-System-Product-Name</em>)
                <ul>
                    <li>2 GPU Nvidia Geforece RTX 3090 (24Gb)</li>
                    <li>ssh on port 22</li>
                </ul>
            </li>
            <li>137.204.107.153 (<em>deeplearn2</em>)
                <ul>
                    <li>2 GPU Titan XP (12 Gb)</li>
                    <li>ssh on port 37335</li>
                </ul>
            </li>
        </ul>
        <p><em>faretra</em> is the <strong>master</strong> node and is the one from which most commands should be
            executed.</p>
        <h2 id="preliminary-steps">Preliminary Steps</h2>
        <ol>
            <li>Make sure you have an account on all 3 servers by logging in with the credential that you have been
                provided</li>
            <li> Change your password with a private one containing at least 10 characters; use lower case and upper
                case letters adding also numbers and symbols</li>
            <li>You should always use the <em>'byobu'</em> terminal (just type <kbd>byobu</kbd> after you login). This way, the
                shell that is opened and on which you will execute the commands remains active even when the terminal is
                closed (this is useful if you want to run long jobs)
            </li>
            <li>
                <p>
                    Install docker rootless by running on each server the script <kbd> install_rootless_docker.sh</kbd>
                </p>
                <p>
                    After the installation is complete, restart the shell and check that docker is working by running <kbd>docker ps</kbd> (check that no errors are returned).
                    <br>
                    If docker is not working try to execute <kbd> systemctl --user start docker </kbd>
                </p>
            </li>
            <li>
                <p>Connect into the master node (137.204.107.40) and try to execute: <kbd> sinfo
                        --Format=NodeAddr,CPUs:10,Gres:35</kbd>
                    <br>
                    the output should be something like:
                </p>
                <pre><samp>NODE_ADDR           CPUS      GRES
137.204.107.40      48        gpu:nvidia_geforce_rtx_3090:4(S:0)
137.204.107.43      20        gpu:nvidia_geforce_rtx_3090:2(S:0)
137.204.107.153     16        gpu:titan_xp:2(S:0)</samp></pre>
            </li>
        </ol>
        <h2 id="file-distribution">File Distribution and Synchronization</h2>
        <p><strong>NB:</strong> We don't have a software that automatically manages the distribution of files. Each
                user must make sure to keep files and folders synchronized on each server. To do so you can use
                <code>unison</code>. 
        <h3>Synchronization with UNISON</h3>        
        Move into your own folder of the main server 137.204.107.40; create the <tt>.unison</tt> folder if it doesn't already exist. Then create a file named <tt>sync_43.prf</tt> with the following content (replace YOUR_HOME with the path to your home directory e.g., <tt>/home/salvatori</tt>):
    <pre>
    root = YOUR_HOME
    root = ssh://137.204.107.43/YOUR_HOME
    sshargs = -p 22

    # Files and Folders to ignore 
    # (see https://www.seas.upenn.edu/~bcpierce/unison/download/releases/beta/unison-manual.html#sec53)
    ignore = Path .*
    ignore = Name .*
    ignore = Name *.pyc
    ignore = Path bin
    ignore = Path miniconda*
    ignore = Path conda*
    ignore = Name __pycache__

    # Other config
    prefer = YOUR_HOME
    auto=true
    </pre>

        Then create another file called <tt>sync_153.prf</tt> in which you replace the ip from 137.204.107.43 to 137.204.107.153 and <tt>sshargs</tt> from <tt>-p 22</tt> to <tt>-p 37335</tt>. The file should look something like
    <pre>
    root = /home/salvatori
    root = ssh://137.204.107.153//home/salvatori
    sshargs = -p 37335

    ignore = Path .*
    ignore = Name .*
    ignore = Name *.pyc
    ignore = Path bin
    ignore = Path miniconda*
    ignore = Path conda*
    ignore = Name __pycache__
    prefer = /home/salvatori

    auto=true
    </pre>
    From now on you can execute the commands <kbd>unison sync_43</kbd> and <kbd>unison sync_153</kbd> to synchornize files between the corresponding servers.
        <!--It is also possible to move files between servers using the <code>scp</code> command. For example, to
        copy the &#39;project&#39; folder
                from the home of server 40 to the home of server 153 you can execute</p>
        <kbd>scp -P 37335 -r /home/&lt;user&gt;/project &lt;username&gt;@137.204.107.153:/home/&lt;user&gt;</kbd>
        <br><br>-->
        <h2 id="executing-tasks-with-slurm">Executing Tasks with SLURM</h2>
        <p><a href="https://slurm.schedmd.com/" target="_blank">SLURM</a> is a cluster manager that allows us to
            dynamically schedule
            and allocate tasks on our GPUs.</p>
        <h3 id="real-time-mode-srun-">Real Time mode (SRUN)</h3>
        <p>The command <a href="https://slurm.schedmd.com/srun.html"><strong>srun</strong></a> can be used to execute
            tasks in <em>real time</em> mode, allocating a certain number of GPUs. <code>srun</code> is
            <strong>interactive and blocking</strong> (the output is redirected to your terminal and no other commands
            can be executed until the task is finished). The <em>srun</em> processes are connected to the shell and, if
            the shell is closed, they are killed (unless you use <em>byobu</em>).
        </p>
        <p>So, once a command is launched with srun:</p>
        <ul>
            <li>the shell <em>waits</em> until the requested resources are available</li>
            <li>once the task is started, the output is redirected to the standard output</li>
        </ul>
        <p>You can use the <code>--pty</code> parameter to enable interactive command mode. For example </p>
        <pre><kbd>srun -N 1 --gpus=nvidia_geforce_rtx_3090:1 --pty bash</kbd></pre>
        <p>opens a bash which will have a dedicated GPU and can be used interactively. The index of the assigned GPU is
            saved in the environment variable <code>CUDA_VISIBLE_DEVICES</code>.</p>
        <ul>
            <li><code>-N 1</code> tells SLURM to run the task in 1 node</li>
            <li><code>--gpus=nvidia_geforce_rtx_3090:1</code> requires to allocate a nvidia_geforce_rtx_3090 GPU (the
                task will be launched on server 40 or server 43 since they are the only one that have that type of GPU);
                titan_xp can be specified instead of nvidia_geforce_rtx_3090 to require 12Gb GPU; or even
                <code>--gpus = 1</code> to require any GPU
            </li>
            <li><code>--pty</code> enables interactive mode</li>
            <li><code>bash</code> is the name of the command you want to execute</li>
        </ul>
        <p><em><strong>NB:</strong> as long as the bash started in this way remains open, the assigned GPU will not be
                usable by other users (even if no process is using it). For this reason, the method just described
                should be used primarily for testing code during development and not for running long tasks.</em></p>
        <p>The standard usage must be without the <code>--pty</code> parameter: once the code has been tested,
            a <code>train.sh</code> script should be created to execute the python code, for example:</p>

        <pre><code class="lang-bash"> #!/bin/bash

    python train.py ...</code></pre>
        <p>Then make the script executable with the command: <kbd>chmod +x train.sh</kbd></p>
        <p>and run with: <kbd>srun -N 1 --gpus=nvidia_geforce_rtx_3090:1 train.sh</kbd></p>
        <p>This way, as soon as the task ends, the resources are freed and usable by other users.</p>

        <h3 id="non-interactive-mode-sbatch-">Non interactive mode (SBATCH)</h3>
        <p><a href="https://slurm.schedmd.com/sbatch.html"><strong>sbatch</strong></a> allows you to launch tasks on the
            cluster in a non-blocking way. Using <code>sbatch</code>, the task is handled in the background by SLURM;
            you can log out, close the terminal, etc. without consequences. The job is no longer linked to the running
            shell.</p>
        <p>By default, standard output and standard error are redirected to a file named
            <code>&quot;slurm-%j.out&quot;</code>, where <code>&quot;%j&quot;</code> is replaced with the job ID. The
            file will be generated on the node where the job was allocated.
        </p>
        <p>The same train script described in the previous section can be run in the background with sbatch with:</p>
        <kbd>sbatch -N 1 --gpus=nvidia_geforce_rtx_3090:1 train.sh</kbd>
        <br><br>

        <h3 id="job-management-and-monitoring">Job management and monitoring</h3>
        <p>You can run the command <a href="https://slurm.schedmd.com/squeue.html"><strong>squeue</strong></a> to get
            information (e.g., JobID, Execution time, NodeHost ...) about running or pending jobs. The output should
            look like this:</p>
        <pre><samp>JOBID PARTITION     NAME     USER       ST     TIME  NODES  NODELIST
1023  main          train.sh salvatori  R      14:52     1  faretra
        </samp></pre>
        <p>To cancel your own job, you can use the command
            <a href="https://slurm.schedmd.com/scancel.html"><strong>scancel</strong></a>, executing: <kbd>scancel
                &lt;job_id&gt;</kbd>
        </p>

        <h2 id="docker">Docker</h2>
        <p>It is possible to use SLURM to start a docker container that uses ONLY the GPU that has been assigned to us
            by the scheduler.</p>
        <p>Suppose we have a python project inside the <code>project</code> folder in our home. Inside the folder we
            have already created an bash script to perform, for example, the model training:</p>
        <pre><code class="lang-bash">#!/bin/bash
        
    python train.py ...</code></pre>
        <p>At this point, we can create a second script <code>train_inside_docker.sh</code>: </p>
        <pre><code class="language-bash">#!/bin/bash
        
    docker run --rm --gpus '"device='$CUDA_VISIBLE_DEVICES'"' -v $HOME:$HOME  &lt;my_image&gt; $HOME/project/train.sh</code></pre>
        <p><code>&lt;my_image&gt;</code> should be replaced with your own docker image containing the python runtime
            environment.</p>
        <p>Make the script executable: <kbd>chmod +x train_inside_docker.sh</kbd></p>

        <p>and run it with SLURM:<br>
            <kbd>srun -N 1 --gpus=nvidia_geforce_rtx_3090:1 train_inside_docker.sh</kbd>
        </p>

        <p>or:<br>
            <kbd>sbatch -N 1 --gpus=nvidia_geforce_rtx_3090:1 train_inside_docker.sh</kbd>
        </p>

    </div>
</body>

</html>